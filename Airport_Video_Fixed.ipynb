{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2B3_ZRmVF1_"
      },
      "source": [
        "# Airport/Station Video Analytics System\n",
        "## Real-time Crowd Density & Abandoned Object Detection\n",
        "\n",
        "**Project Overview:**\n",
        "- Detect overcrowding in designated areas\n",
        "- Identify abandoned objects (bags, luggage)\n",
        "- Generate real-time alerts for security personnel\n",
        "- Track people density and movement patterns\n",
        "\n",
        "**Technologies Used:**\n",
        "- YOLOv8 for object detection\n",
        "- OpenCV for video processing\n",
        "- Background subtraction for abandoned object detection\n",
        "- Real-time alert system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVkphp7ZVF2G"
      },
      "source": [
        "## 1. Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pGcLhlvVF2K",
        "outputId": "d8f2a627-617d-47e5-d1ff-09ea2497cdcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.4.14-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.13.0.92)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.13.0.92)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cpu)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (26.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.4.14-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.4.14 ultralytics-thop-2.0.18\n",
            "Collecting supervision\n",
            "  Downloading supervision-0.27.0.post1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.12/dist-packages (from supervision) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from supervision) (6.0.3)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.12/dist-packages (from supervision) (11.3.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.12/dist-packages (from supervision) (4.67.3)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.12/dist-packages (from supervision) (4.13.0.92)\n",
            "Collecting pyDeprecate>=0.4.0 (from supervision)\n",
            "  Downloading pydeprecate-0.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (26.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (2026.1.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.17.0)\n",
            "Downloading supervision-0.27.0.post1-py3-none-any.whl (217 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m217.4/217.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeprecate-0.4.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: pyDeprecate, supervision\n",
            "Successfully installed pyDeprecate-0.4.0 supervision-0.27.0.post1\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install ultralytics opencv-python-headless numpy matplotlib pillow\n",
        "!pip install supervision scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7ppBQZSVF2O",
        "outputId": "67481dff-f744-4a6e-feb2-6f8023fdabea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "‚úÖ All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "from collections import defaultdict, deque\n",
        "from datetime import datetime\n",
        "import time\n",
        "from IPython.display import clear_output, Image, display\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IjXo-paVF2R"
      },
      "source": [
        "## 2. Configuration and Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cook6eQ-VF2S",
        "outputId": "c0bae594-8fbe-43ca-d60c-aa1a134ddfc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Configuration loaded!\n"
          ]
        }
      ],
      "source": [
        "# Configuration Parameters\n",
        "class Config:\n",
        "    # Model settings\n",
        "    MODEL_NAME = 'yolov8n.pt'\n",
        "    CONFIDENCE_THRESHOLD = 0.5\n",
        "    IOU_THRESHOLD = 0.45\n",
        "\n",
        "    # Crowd detection settings\n",
        "    OVERCROWDING_THRESHOLD = 15\n",
        "    HIGH_DENSITY_THRESHOLD = 10\n",
        "\n",
        "    # Abandoned object detection settings\n",
        "    ABANDONMENT_TIME = 30\n",
        "    PROXIMITY_THRESHOLD = 100\n",
        "    STATIC_OBJECT_TIME = 10\n",
        "\n",
        "    # Background subtraction\n",
        "    BG_HISTORY = 500\n",
        "    BG_THRESHOLD = 16\n",
        "    BG_LEARNING_RATE = 0.01\n",
        "\n",
        "    # Visualization\n",
        "    FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    FONT_SCALE = 0.6\n",
        "    THICKNESS = 2\n",
        "\n",
        "    # Alert colors (BGR format)\n",
        "    COLOR_SAFE = (0, 255, 0)\n",
        "    COLOR_WARNING = (0, 165, 255)\n",
        "    COLOR_DANGER = (0, 0, 255)\n",
        "    COLOR_ABANDONED = (255, 0, 255)\n",
        "\n",
        "config = Config()\n",
        "print(\"‚úÖ Configuration loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VZddPMgVF2U"
      },
      "source": [
        "## 3. Load YOLO Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH5C7WKIVF2Y",
        "outputId": "6c1a3fb0-8db9-4646-d93b-8a375baa735d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading YOLOv8 model...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov8n.pt to 'yolov8n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.2MB 61.3MB/s 0.1s\n",
            "‚úÖ Model loaded: yolov8n.pt\n",
            "\n",
            "Detectable classes: 80\n",
            "Person class ID: 0\n"
          ]
        }
      ],
      "source": [
        "# Load YOLOv8 model\n",
        "print(\"Loading YOLOv8 model...\")\n",
        "model = YOLO(config.MODEL_NAME)\n",
        "print(f\"‚úÖ Model loaded: {config.MODEL_NAME}\")\n",
        "\n",
        "# Get class names\n",
        "class_names = model.names\n",
        "print(f\"\\nDetectable classes: {len(class_names)}\")\n",
        "print(f\"Person class ID: {list(class_names.values()).index('person')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCPdTzOZVF2c"
      },
      "source": [
        "## 4. Define Region of Interest (ROI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SlSIfRZVF2d",
        "outputId": "691fdde8-7e1c-44da-d481-be16879ce0e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ROI class defined!\n"
          ]
        }
      ],
      "source": [
        "class ROI:\n",
        "    def __init__(self, name, polygon_points):\n",
        "        self.name = name\n",
        "        self.polygon = np.array(polygon_points, np.int32)\n",
        "        self.person_count = 0\n",
        "        self.status = \"SAFE\"\n",
        "        self.color = config.COLOR_SAFE\n",
        "\n",
        "    def is_point_inside(self, point):\n",
        "        return cv2.pointPolygonTest(self.polygon, point, False) >= 0\n",
        "\n",
        "    def update_status(self):\n",
        "        if self.person_count >= config.OVERCROWDING_THRESHOLD:\n",
        "            self.status = \"OVERCROWDED\"\n",
        "            self.color = config.COLOR_DANGER\n",
        "        elif self.person_count >= config.HIGH_DENSITY_THRESHOLD:\n",
        "            self.status = \"HIGH DENSITY\"\n",
        "            self.color = config.COLOR_WARNING\n",
        "        else:\n",
        "            self.status = \"SAFE\"\n",
        "            self.color = config.COLOR_SAFE\n",
        "        return self.status\n",
        "\n",
        "def create_default_rois(frame_width, frame_height):\n",
        "    rois = [\n",
        "        ROI(\"Checkpoint Area\", [\n",
        "            [int(frame_width * 0.1), int(frame_height * 0.3)],\n",
        "            [int(frame_width * 0.5), int(frame_height * 0.3)],\n",
        "            [int(frame_width * 0.5), int(frame_height * 0.7)],\n",
        "            [int(frame_width * 0.1), int(frame_height * 0.7)]\n",
        "        ]),\n",
        "        ROI(\"Waiting Area\", [\n",
        "            [int(frame_width * 0.5), int(frame_height * 0.3)],\n",
        "            [int(frame_width * 0.9), int(frame_height * 0.3)],\n",
        "            [int(frame_width * 0.9), int(frame_height * 0.7)],\n",
        "            [int(frame_width * 0.5), int(frame_height * 0.7)]\n",
        "        ])\n",
        "    ]\n",
        "    return rois\n",
        "\n",
        "print(\"‚úÖ ROI class defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6RHkMVZVF2f"
      },
      "source": [
        "## 5. Abandoned Object Detection System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muEtfvSdVF2g",
        "outputId": "3d5d6bd9-76d8-4eaf-d75e-d2204b8ba48d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Abandoned Object Detector class defined!\n"
          ]
        }
      ],
      "source": [
        "class AbandonedObjectDetector:\n",
        "    def __init__(self):\n",
        "        self.tracked_objects = {}\n",
        "        self.abandoned_objects = {}\n",
        "        self.next_id = 0\n",
        "        self.trackable_classes = ['backpack', 'handbag', 'suitcase', 'umbrella', 'bottle']\n",
        "\n",
        "    def calculate_distance(self, point1, point2):\n",
        "        return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)\n",
        "\n",
        "    def is_owner_nearby(self, obj_position, person_positions):\n",
        "        for person_pos in person_positions:\n",
        "            if self.calculate_distance(obj_position, person_pos) < config.PROXIMITY_THRESHOLD:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def update(self, detections, person_positions, current_time):\n",
        "        current_objects = []\n",
        "\n",
        "        for bbox, class_name in detections:\n",
        "            if class_name in self.trackable_classes:\n",
        "                x1, y1, x2, y2 = bbox\n",
        "                center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "                current_objects.append((center, class_name, bbox))\n",
        "\n",
        "        matched_ids = set()\n",
        "        for center, class_name, bbox in current_objects:\n",
        "            best_match = None\n",
        "            best_distance = float('inf')\n",
        "\n",
        "            for obj_id, obj_data in self.tracked_objects.items():\n",
        "                if obj_id in matched_ids:\n",
        "                    continue\n",
        "                distance = self.calculate_distance(center, obj_data['position'])\n",
        "                if distance < 50 and distance < best_distance:\n",
        "                    best_distance = distance\n",
        "                    best_match = obj_id\n",
        "\n",
        "            if best_match is not None:\n",
        "                matched_ids.add(best_match)\n",
        "                obj_data = self.tracked_objects[best_match]\n",
        "\n",
        "                if self.calculate_distance(center, obj_data['position']) < 10:\n",
        "                    obj_data['static_time'] = current_time - obj_data['first_seen']\n",
        "                else:\n",
        "                    obj_data['first_seen'] = current_time\n",
        "                    obj_data['static_time'] = 0\n",
        "\n",
        "                obj_data['position'] = center\n",
        "                obj_data['bbox'] = bbox\n",
        "                obj_data['last_seen'] = current_time\n",
        "                obj_data['owner_nearby'] = self.is_owner_nearby(center, person_positions)\n",
        "\n",
        "                if (obj_data['static_time'] >= config.STATIC_OBJECT_TIME and\n",
        "                    not obj_data['owner_nearby'] and\n",
        "                    (current_time - obj_data['last_owner_time']) >= config.ABANDONMENT_TIME):\n",
        "                    if best_match not in self.abandoned_objects:\n",
        "                        self.abandoned_objects[best_match] = {\n",
        "                            'position': center,\n",
        "                            'bbox': bbox,\n",
        "                            'class': class_name,\n",
        "                            'abandoned_time': current_time\n",
        "                        }\n",
        "            else:\n",
        "                owner_nearby = self.is_owner_nearby(center, person_positions)\n",
        "                self.tracked_objects[self.next_id] = {\n",
        "                    'position': center,\n",
        "                    'bbox': bbox,\n",
        "                    'class': class_name,\n",
        "                    'first_seen': current_time,\n",
        "                    'last_seen': current_time,\n",
        "                    'static_time': 0,\n",
        "                    'owner_nearby': owner_nearby,\n",
        "                    'last_owner_time': current_time\n",
        "                }\n",
        "                self.next_id += 1\n",
        "\n",
        "        for obj_id, obj_data in self.tracked_objects.items():\n",
        "            if obj_data['owner_nearby']:\n",
        "                obj_data['last_owner_time'] = current_time\n",
        "\n",
        "        to_remove = []\n",
        "        for obj_id, obj_data in self.tracked_objects.items():\n",
        "            if current_time - obj_data['last_seen'] > 5:\n",
        "                to_remove.append(obj_id)\n",
        "\n",
        "        for obj_id in to_remove:\n",
        "            del self.tracked_objects[obj_id]\n",
        "            if obj_id in self.abandoned_objects:\n",
        "                del self.abandoned_objects[obj_id]\n",
        "\n",
        "        return self.abandoned_objects\n",
        "\n",
        "print(\"‚úÖ Abandoned Object Detector class defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmMZ-dIvVF2j"
      },
      "source": [
        "## 6. Alert System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UwwMt-WVF2j",
        "outputId": "f16f1968-03ec-4440-a229-1521be8f3df6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Alert System initialized!\n"
          ]
        }
      ],
      "source": [
        "class AlertSystem:\n",
        "    def __init__(self):\n",
        "        self.alerts = []\n",
        "        self.alert_cooldown = {}\n",
        "\n",
        "    def add_alert(self, alert_type, message, severity=\"INFO\"):\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        alert_key = f\"{alert_type}_{message}\"\n",
        "        current_time = time.time()\n",
        "\n",
        "        if alert_key in self.alert_cooldown:\n",
        "            if current_time - self.alert_cooldown[alert_key] < 10:\n",
        "                return\n",
        "\n",
        "        self.alert_cooldown[alert_key] = current_time\n",
        "\n",
        "        alert = {\n",
        "            'timestamp': timestamp,\n",
        "            'type': alert_type,\n",
        "            'message': message,\n",
        "            'severity': severity\n",
        "        }\n",
        "        self.alerts.append(alert)\n",
        "\n",
        "        severity_symbol = \"‚ö†Ô∏è\" if severity == \"WARNING\" else \"üö®\" if severity == \"CRITICAL\" else \"‚ÑπÔ∏è\"\n",
        "        print(f\"{severity_symbol} [{timestamp}] {alert_type}: {message}\")\n",
        "\n",
        "    def get_recent_alerts(self, n=5):\n",
        "        return self.alerts[-n:] if len(self.alerts) >= n else self.alerts\n",
        "\n",
        "alert_system = AlertSystem()\n",
        "print(\"‚úÖ Alert System initialized!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zzCKqZSVF2l"
      },
      "source": [
        "## 7. Main Video Analytics Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RaJ5ooP-VF2l"
      },
      "outputs": [],
      "source": [
        "def draw_dashboard(frame, rois, total_people, abandoned_count, fps, alerts):\n",
        "    h, w = frame.shape[:2]\n",
        "\n",
        "    overlay = frame.copy()\n",
        "    cv2.rectangle(overlay, (10, 10), (400, 200), (0, 0, 0), -1)\n",
        "    frame = cv2.addWeighted(overlay, 0.7, frame, 0.3, 0)\n",
        "\n",
        "    cv2.putText(frame, \"Airport Security Analytics\", (20, 35),\n",
        "                config.FONT, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "    cv2.putText(frame, f\"Total People: {total_people}\", (20, 65),\n",
        "                config.FONT, 0.5, (255, 255, 255), 1)\n",
        "    cv2.putText(frame, f\"Abandoned Objects: {abandoned_count}\", (20, 90),\n",
        "                config.FONT, 0.5, (255, 100, 100) if abandoned_count > 0 else (255, 255, 255), 1)\n",
        "    cv2.putText(frame, f\"FPS: {fps:.1f}\", (20, 115),\n",
        "                config.FONT, 0.5, (255, 255, 255), 1)\n",
        "\n",
        "    y_offset = 140\n",
        "    for roi in rois:\n",
        "        status_text = f\"{roi.name}: {roi.person_count} ({roi.status})\"\n",
        "        cv2.putText(frame, status_text, (20, y_offset),\n",
        "                    config.FONT, 0.4, roi.color, 1)\n",
        "        y_offset += 20\n",
        "\n",
        "    if alerts:\n",
        "        alert_overlay = frame.copy()\n",
        "        cv2.rectangle(alert_overlay, (w - 410, h - 110), (w - 10, h - 10), (0, 0, 0), -1)\n",
        "        frame = cv2.addWeighted(alert_overlay, 0.7, frame, 0.3, 0)\n",
        "\n",
        "        cv2.putText(frame, \"Recent Alerts:\", (w - 400, h - 90),\n",
        "                    config.FONT, 0.5, (255, 255, 255), 1)\n",
        "\n",
        "        for idx, alert in enumerate(alerts[-3:]):\n",
        "            alert_text = f\"{alert['type'][:20]}...\"\n",
        "            color = (0, 255, 255) if alert['severity'] == \"WARNING\" else (0, 0, 255)\n",
        "            cv2.putText(frame, alert_text, (w - 400, h - 65 + idx * 20),\n",
        "                        config.FONT, 0.4, color, 1)\n",
        "\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od7ZSYILVF2n",
        "outputId": "be3cf883-a1c6-4430-f64d-8c7d546110a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Video processing pipeline defined!\n"
          ]
        }
      ],
      "source": [
        "def process_video(video_path, output_path=None, max_frames=None):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"‚ùå Error: Cannot open video file {video_path}\")\n",
        "        return\n",
        "\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps_video = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    print(f\"\\nüìπ Video Info:\")\n",
        "    print(f\"   Resolution: {frame_width}x{frame_height}\")\n",
        "    print(f\"   FPS: {fps_video}\")\n",
        "    print(f\"   Total Frames: {total_frames}\")\n",
        "\n",
        "    rois = create_default_rois(frame_width, frame_height)\n",
        "    abandoned_detector = AbandonedObjectDetector()\n",
        "\n",
        "    writer = None\n",
        "    if output_path:\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        writer = cv2.VideoWriter(output_path, fourcc, fps_video, (frame_width, frame_height))\n",
        "\n",
        "    frame_count = 0\n",
        "    start_time = time.time()\n",
        "    fps_deque = deque(maxlen=30)\n",
        "\n",
        "    print(\"\\nüöÄ Starting video processing...\\n\")\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "            if max_frames and frame_count > max_frames:\n",
        "                break\n",
        "\n",
        "            frame_start = time.time()\n",
        "            current_time = time.time() - start_time\n",
        "\n",
        "            results = model(frame, conf=config.CONFIDENCE_THRESHOLD,\n",
        "                          iou=config.IOU_THRESHOLD, verbose=False)[0]\n",
        "\n",
        "            person_positions = []\n",
        "            object_detections = []\n",
        "\n",
        "            for box in results.boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                conf = float(box.conf[0])\n",
        "                cls = int(box.cls[0])\n",
        "                class_name = class_names[cls]\n",
        "\n",
        "                center_x = (x1 + x2) // 2\n",
        "                center_y = (y1 + y2) // 2\n",
        "\n",
        "                if class_name == 'person':\n",
        "                    person_positions.append((center_x, center_y))\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                    cv2.putText(frame, f\"Person {conf:.2f}\", (x1, y1 - 10),\n",
        "                               config.FONT, 0.5, (0, 255, 0), 1)\n",
        "                else:\n",
        "                    object_detections.append(((x1, y1, x2, y2), class_name))\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
        "                    cv2.putText(frame, f\"{class_name} {conf:.2f}\", (x1, y1 - 10),\n",
        "                               config.FONT, 0.4, (255, 255, 0), 1)\n",
        "\n",
        "            abandoned_objects = abandoned_detector.update(\n",
        "                object_detections, person_positions, current_time\n",
        "            )\n",
        "\n",
        "            for obj_id, obj_data in abandoned_objects.items():\n",
        "                x1, y1, x2, y2 = obj_data['bbox']\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), config.COLOR_ABANDONED, 3)\n",
        "                cv2.putText(frame, \"ABANDONED!\", (x1, y1 - 25),\n",
        "                           config.FONT, 0.6, config.COLOR_ABANDONED, 2)\n",
        "\n",
        "                time_abandoned = int(current_time - obj_data['abandoned_time'])\n",
        "                cv2.putText(frame, f\"{time_abandoned}s\", (x1, y1 - 5),\n",
        "                           config.FONT, 0.5, config.COLOR_ABANDONED, 1)\n",
        "\n",
        "                alert_system.add_alert(\n",
        "                    \"ABANDONED OBJECT\",\n",
        "                    f\"{obj_data['class']} at ({obj_data['position'][0]}, {obj_data['position'][1]})\",\n",
        "                    \"CRITICAL\"\n",
        "                )\n",
        "\n",
        "            for roi in rois:\n",
        "                roi.person_count = 0\n",
        "                for px, py in person_positions:\n",
        "                    if roi.is_point_inside((px, py)):\n",
        "                        roi.person_count += 1\n",
        "                        cv2.circle(frame, (px, py), 5, roi.color, -1)\n",
        "\n",
        "                status = roi.update_status()\n",
        "                cv2.polylines(frame, [roi.polygon], True, roi.color, 2)\n",
        "\n",
        "                label_pos = tuple(roi.polygon[0])\n",
        "                cv2.putText(frame, f\"{roi.name}: {roi.person_count}\", label_pos,\n",
        "                           config.FONT, 0.6, roi.color, 2)\n",
        "\n",
        "                if status == \"OVERCROWDED\":\n",
        "                    alert_system.add_alert(\n",
        "                        \"OVERCROWDING\",\n",
        "                        f\"{roi.name} has {roi.person_count} people (threshold: {config.OVERCROWDING_THRESHOLD})\",\n",
        "                        \"CRITICAL\"\n",
        "                    )\n",
        "                elif status == \"HIGH DENSITY\":\n",
        "                    alert_system.add_alert(\n",
        "                        \"HIGH DENSITY\",\n",
        "                        f\"{roi.name} has {roi.person_count} people\",\n",
        "                        \"WARNING\"\n",
        "                    )\n",
        "\n",
        "            frame_time = time.time() - frame_start\n",
        "            fps_deque.append(1.0 / frame_time if frame_time > 0 else 0)\n",
        "            avg_fps = sum(fps_deque) / len(fps_deque)\n",
        "\n",
        "            frame = draw_dashboard(\n",
        "                frame, rois, len(person_positions),\n",
        "                len(abandoned_objects), avg_fps,\n",
        "                alert_system.get_recent_alerts()\n",
        "            )\n",
        "\n",
        "            if writer:\n",
        "                writer.write(frame)\n",
        "\n",
        "            if frame_count % 30 == 0:\n",
        "                print(f\"\\rProcessed: {frame_count}/{total_frames if not max_frames else max_frames} frames | \"\n",
        "                      f\"FPS: {avg_fps:.1f} | People: {len(person_positions)} | \"\n",
        "                      f\"Abandoned: {len(abandoned_objects)}\", end=\"\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\n‚ö†Ô∏è Processing interrupted by user\")\n",
        "\n",
        "    finally:\n",
        "        cap.release()\n",
        "        if writer:\n",
        "            writer.release()\n",
        "\n",
        "        print(f\"\\n\\n‚úÖ Processing complete!\")\n",
        "        print(f\"   Processed {frame_count} frames\")\n",
        "        print(f\"   Total alerts generated: {len(alert_system.alerts)}\")\n",
        "        if output_path:\n",
        "            print(f\"   Output saved to: {output_path}\")\n",
        "\n",
        "print(\"‚úÖ Video processing pipeline defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIdnh8stVF2r"
      },
      "source": [
        "## 8. Upload Test Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "A9pQlvKyVF2t",
        "outputId": "d6443f0a-4e07-462e-80ad-c220278d9a67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your video file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-83d2adc7-026f-4c2a-9dea-ea154462ba88\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-83d2adc7-026f-4c2a-9dea-ea154462ba88\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 13606911-uhd_3840_2160_24fps.mp4 to 13606911-uhd_3840_2160_24fps.mp4\n",
            "‚úÖ Video uploaded: 13606911-uhd_3840_2160_24fps.mp4\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"Upload your video file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "video_path = list(uploaded.keys())[0]\n",
        "print(f\"‚úÖ Video uploaded: {video_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an4QboxvVF2u"
      },
      "source": [
        "## 9. Run Video Analytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyygOFKaVF2u",
        "outputId": "97beb9dc-57c0-4be0-b857-9b53dcfe3960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìπ Video Info:\n",
            "   Resolution: 2560x1440\n",
            "   FPS: 23\n",
            "   Total Frames: 349\n",
            "\n",
            "üöÄ Starting video processing...\n",
            "\n",
            "Processed: 330/349 frames | FPS: 9.1 | People: 8 | Abandoned: 0\n",
            "\n",
            "‚úÖ Processing complete!\n",
            "   Processed 349 frames\n",
            "   Total alerts generated: 0\n",
            "   Output saved to: output_analyzed.mp4\n"
          ]
        }
      ],
      "source": [
        "output_video_path = \"output_analyzed.mp4\"\n",
        "\n",
        "process_video(\n",
        "    video_path=video_path,\n",
        "    output_path=output_video_path,\n",
        "    max_frames=None\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR4EJiobVF2v"
      },
      "source": [
        "## 10. Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "azlk3-DmVF2v",
        "outputId": "680949ad-5307-4e61-9b99-bbe793cc27fc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_268bad6f-03a2-48d0-a4a9-75964941e6f5\", \"output_analyzed.mp4\", 64777266)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Download started: output_analyzed.mp4\n"
          ]
        }
      ],
      "source": [
        "if os.path.exists(output_video_path):\n",
        "    files.download(output_video_path)\n",
        "    print(f\"‚úÖ Download started: {output_video_path}\")\n",
        "else:\n",
        "    print(\"‚ùå Output video not found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3Sf8qR9VF2w"
      },
      "source": [
        "## 11. Generate Alert Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUZr3z5VVF2x",
        "outputId": "0e384429-ba20-406a-a291-f7b1548027e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No alerts generated during processing\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "if alert_system.alerts:\n",
        "    df_alerts = pd.DataFrame(alert_system.alerts)\n",
        "\n",
        "    print(\"\\nüìä ALERT SUMMARY\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Total Alerts: {len(df_alerts)}\")\n",
        "    print(f\"\\nAlerts by Type:\")\n",
        "    print(df_alerts['type'].value_counts())\n",
        "    print(f\"\\nAlerts by Severity:\")\n",
        "    print(df_alerts['severity'].value_counts())\n",
        "\n",
        "    print(\"\\n\\nüìã RECENT ALERTS (Last 10)\")\n",
        "    print(\"=\" * 70)\n",
        "    print(df_alerts[['timestamp', 'type', 'message', 'severity']].tail(10).to_string(index=False))\n",
        "\n",
        "    report_path = \"alert_report.csv\"\n",
        "    df_alerts.to_csv(report_path, index=False)\n",
        "    print(f\"\\n‚úÖ Alert report saved to: {report_path}\")\n",
        "\n",
        "    files.download(report_path)\n",
        "else:\n",
        "    print(\"No alerts generated during processing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxFb95_bVF2x"
      },
      "source": [
        "## 12. Visualize Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4PxZQibAVF2y"
      },
      "outputs": [],
      "source": [
        "if alert_system.alerts:\n",
        "    df = pd.DataFrame(alert_system.alerts)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    df['type'].value_counts().plot(kind='bar', ax=axes[0], color='steelblue')\n",
        "    axes[0].set_title('Alert Types Distribution', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('Alert Type')\n",
        "    axes[0].set_ylabel('Count')\n",
        "    axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    severity_colors = {'INFO': 'green', 'WARNING': 'orange', 'CRITICAL': 'red'}\n",
        "    severity_counts = df['severity'].value_counts()\n",
        "    colors = [severity_colors.get(sev, 'gray') for sev in severity_counts.index]\n",
        "    severity_counts.plot(kind='pie', ax=axes[1], autopct='%1.1f%%', colors=colors)\n",
        "    axes[1].set_title('Alert Severity Distribution', fontsize=14, fontweight='bold')\n",
        "    axes[1].set_ylabel('')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('alert_statistics.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n‚úÖ Visualization saved as alert_statistics.png\")\n",
        "    files.download('alert_statistics.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeJJHpimVF2z"
      },
      "source": [
        "## 13. Project Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "dlWuVcAFVF20",
        "outputId": "bafd5231-8ea3-4baa-85b2-01dfe983c008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Airport/Station Video Analytics System\n",
            "=====================================\n",
            "\n",
            "Date: 2026-02-16 12:07:11\n",
            "Model: YOLOv8n (Nano)\n",
            "Framework: Ultralytics YOLO + OpenCV\n",
            "\n",
            "CAPABILITIES:\n",
            "- Real-time people detection and counting\n",
            "- Crowd density monitoring with zone-based analysis\n",
            "- Overcrowding detection with configurable thresholds\n",
            "- Abandoned object detection (bags, luggage, etc.)\n",
            "- Automated alert system with severity levels\n",
            "- Multi-zone Region of Interest (ROI) monitoring\n",
            "\n",
            "Total Alerts Generated: 0\n",
            "\n",
            "\n",
            "‚úÖ Project summary saved!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_80fbb50f-7af6-470a-8ce1-033a39a84223\", \"project_summary.txt\", 499)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "summary_text = f\"Airport/Station Video Analytics System\\n\"\n",
        "summary_text += f\"=====================================\\n\\n\"\n",
        "summary_text += f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
        "summary_text += f\"Model: YOLOv8n (Nano)\\n\"\n",
        "summary_text += f\"Framework: Ultralytics YOLO + OpenCV\\n\\n\"\n",
        "summary_text += f\"CAPABILITIES:\\n\"\n",
        "summary_text += f\"- Real-time people detection and counting\\n\"\n",
        "summary_text += f\"- Crowd density monitoring with zone-based analysis\\n\"\n",
        "summary_text += f\"- Overcrowding detection with configurable thresholds\\n\"\n",
        "summary_text += f\"- Abandoned object detection (bags, luggage, etc.)\\n\"\n",
        "summary_text += f\"- Automated alert system with severity levels\\n\"\n",
        "summary_text += f\"- Multi-zone Region of Interest (ROI) monitoring\\n\\n\"\n",
        "summary_text += f\"Total Alerts Generated: {len(alert_system.alerts)}\\n\"\n",
        "\n",
        "print(summary_text)\n",
        "\n",
        "with open('project_summary.txt', 'w') as f:\n",
        "    f.write(summary_text)\n",
        "\n",
        "print(\"\\n‚úÖ Project summary saved!\")\n",
        "files.download('project_summary.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwWYn9LaVF21"
      },
      "source": [
        "## üéì Learning Resources & Next Steps\n",
        "\n",
        "### Key Concepts Covered:\n",
        "1. **Object Detection**: YOLOv8 for real-time detection\n",
        "2. **Object Tracking**: Proximity-based tracking\n",
        "3. **Spatial Analysis**: ROI-based zone monitoring\n",
        "4. **Temporal Analysis**: Time-based abandonment detection\n",
        "5. **Alert Systems**: Multi-level severity alerts\n",
        "\n",
        "### Future Enhancements:\n",
        "- Add DeepSORT for better object tracking\n",
        "- Implement trajectory analysis\n",
        "- Add behavior recognition (fighting, running)\n",
        "- Integrate with databases (MongoDB, PostgreSQL)\n",
        "- Build REST API with Flask/FastAPI\n",
        "- Create web dashboard with real-time updates\n",
        "- Add email/SMS notifications\n",
        "- Implement multi-camera fusion\n",
        "\n",
        "### Deployment Options:\n",
        "- **Edge**: NVIDIA Jetson Nano/Xavier\n",
        "- **Cloud**: AWS/GCP/Azure with Docker\n",
        "- **Hybrid**: Edge detection + Cloud analytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GHeQqiU-WQbM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}