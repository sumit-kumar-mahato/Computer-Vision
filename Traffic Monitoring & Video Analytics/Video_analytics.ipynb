{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airport/Station Video Analytics System\n",
    "## Real-time Crowd Density & Abandoned Object Detection\n",
    "\n",
    "**Project Overview:**\n",
    "- Detect overcrowding in designated areas\n",
    "- Identify abandoned objects (bags, luggage)\n",
    "- Generate real-time alerts for security personnel\n",
    "- Track people density and movement patterns\n",
    "\n",
    "**Technologies Used:**\n",
    "- YOLOv8 for object detection\n",
    "- OpenCV for video processing\n",
    "- Background subtraction for abandoned object detection\n",
    "- Real-time alert system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install ultralytics opencv-python-headless numpy matplotlib pillow\n",
    "!pip install supervision scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict, deque\n",
    "from datetime import datetime\n",
    "import time\n",
    "from IPython.display import clear_output, Image, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Parameters\n",
    "class Config:\n",
    "    # Model settings\n",
    "    MODEL_NAME = 'yolov8n.pt'\n",
    "    CONFIDENCE_THRESHOLD = 0.5\n",
    "    IOU_THRESHOLD = 0.45\n",
    "    \n",
    "    # Crowd detection settings\n",
    "    OVERCROWDING_THRESHOLD = 15\n",
    "    HIGH_DENSITY_THRESHOLD = 10\n",
    "    \n",
    "    # Abandoned object detection settings\n",
    "    ABANDONMENT_TIME = 30\n",
    "    PROXIMITY_THRESHOLD = 100\n",
    "    STATIC_OBJECT_TIME = 10\n",
    "    \n",
    "    # Background subtraction\n",
    "    BG_HISTORY = 500\n",
    "    BG_THRESHOLD = 16\n",
    "    BG_LEARNING_RATE = 0.01\n",
    "    \n",
    "    # Visualization\n",
    "    FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    FONT_SCALE = 0.6\n",
    "    THICKNESS = 2\n",
    "    \n",
    "    # Alert colors (BGR format)\n",
    "    COLOR_SAFE = (0, 255, 0)\n",
    "    COLOR_WARNING = (0, 165, 255)\n",
    "    COLOR_DANGER = (0, 0, 255)\n",
    "    COLOR_ABANDONED = (255, 0, 255)\n",
    "\n",
    "config = Config()\n",
    "print(\"‚úÖ Configuration loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv8 model\n",
    "print(\"Loading YOLOv8 model...\")\n",
    "model = YOLO(config.MODEL_NAME)\n",
    "print(f\"‚úÖ Model loaded: {config.MODEL_NAME}\")\n",
    "\n",
    "# Get class names\n",
    "class_names = model.names\n",
    "print(f\"\\nDetectable classes: {len(class_names)}\")\n",
    "print(f\"Person class ID: {list(class_names.values()).index('person')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Region of Interest (ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROI:\n",
    "    def __init__(self, name, polygon_points):\n",
    "        self.name = name\n",
    "        self.polygon = np.array(polygon_points, np.int32)\n",
    "        self.person_count = 0\n",
    "        self.status = \"SAFE\"\n",
    "        self.color = config.COLOR_SAFE\n",
    "    \n",
    "    def is_point_inside(self, point):\n",
    "        return cv2.pointPolygonTest(self.polygon, point, False) >= 0\n",
    "    \n",
    "    def update_status(self):\n",
    "        if self.person_count >= config.OVERCROWDING_THRESHOLD:\n",
    "            self.status = \"OVERCROWDED\"\n",
    "            self.color = config.COLOR_DANGER\n",
    "        elif self.person_count >= config.HIGH_DENSITY_THRESHOLD:\n",
    "            self.status = \"HIGH DENSITY\"\n",
    "            self.color = config.COLOR_WARNING\n",
    "        else:\n",
    "            self.status = \"SAFE\"\n",
    "            self.color = config.COLOR_SAFE\n",
    "        return self.status\n",
    "\n",
    "def create_default_rois(frame_width, frame_height):\n",
    "    rois = [\n",
    "        ROI(\"Checkpoint Area\", [\n",
    "            [int(frame_width * 0.1), int(frame_height * 0.3)],\n",
    "            [int(frame_width * 0.5), int(frame_height * 0.3)],\n",
    "            [int(frame_width * 0.5), int(frame_height * 0.7)],\n",
    "            [int(frame_width * 0.1), int(frame_height * 0.7)]\n",
    "        ]),\n",
    "        ROI(\"Waiting Area\", [\n",
    "            [int(frame_width * 0.5), int(frame_height * 0.3)],\n",
    "            [int(frame_width * 0.9), int(frame_height * 0.3)],\n",
    "            [int(frame_width * 0.9), int(frame_height * 0.7)],\n",
    "            [int(frame_width * 0.5), int(frame_height * 0.7)]\n",
    "        ])\n",
    "    ]\n",
    "    return rois\n",
    "\n",
    "print(\"‚úÖ ROI class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Abandoned Object Detection System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbandonedObjectDetector:\n",
    "    def __init__(self):\n",
    "        self.tracked_objects = {}\n",
    "        self.abandoned_objects = {}\n",
    "        self.next_id = 0\n",
    "        self.trackable_classes = ['backpack', 'handbag', 'suitcase', 'umbrella', 'bottle']\n",
    "        \n",
    "    def calculate_distance(self, point1, point2):\n",
    "        return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)\n",
    "    \n",
    "    def is_owner_nearby(self, obj_position, person_positions):\n",
    "        for person_pos in person_positions:\n",
    "            if self.calculate_distance(obj_position, person_pos) < config.PROXIMITY_THRESHOLD:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def update(self, detections, person_positions, current_time):\n",
    "        current_objects = []\n",
    "        \n",
    "        for bbox, class_name in detections:\n",
    "            if class_name in self.trackable_classes:\n",
    "                x1, y1, x2, y2 = bbox\n",
    "                center = ((x1 + x2) // 2, (y1 + y2) // 2)\n",
    "                current_objects.append((center, class_name, bbox))\n",
    "        \n",
    "        matched_ids = set()\n",
    "        for center, class_name, bbox in current_objects:\n",
    "            best_match = None\n",
    "            best_distance = float('inf')\n",
    "            \n",
    "            for obj_id, obj_data in self.tracked_objects.items():\n",
    "                if obj_id in matched_ids:\n",
    "                    continue\n",
    "                distance = self.calculate_distance(center, obj_data['position'])\n",
    "                if distance < 50 and distance < best_distance:\n",
    "                    best_distance = distance\n",
    "                    best_match = obj_id\n",
    "            \n",
    "            if best_match is not None:\n",
    "                matched_ids.add(best_match)\n",
    "                obj_data = self.tracked_objects[best_match]\n",
    "                \n",
    "                if self.calculate_distance(center, obj_data['position']) < 10:\n",
    "                    obj_data['static_time'] = current_time - obj_data['first_seen']\n",
    "                else:\n",
    "                    obj_data['first_seen'] = current_time\n",
    "                    obj_data['static_time'] = 0\n",
    "                \n",
    "                obj_data['position'] = center\n",
    "                obj_data['bbox'] = bbox\n",
    "                obj_data['last_seen'] = current_time\n",
    "                obj_data['owner_nearby'] = self.is_owner_nearby(center, person_positions)\n",
    "                \n",
    "                if (obj_data['static_time'] >= config.STATIC_OBJECT_TIME and \n",
    "                    not obj_data['owner_nearby'] and\n",
    "                    (current_time - obj_data['last_owner_time']) >= config.ABANDONMENT_TIME):\n",
    "                    if best_match not in self.abandoned_objects:\n",
    "                        self.abandoned_objects[best_match] = {\n",
    "                            'position': center,\n",
    "                            'bbox': bbox,\n",
    "                            'class': class_name,\n",
    "                            'abandoned_time': current_time\n",
    "                        }\n",
    "            else:\n",
    "                owner_nearby = self.is_owner_nearby(center, person_positions)\n",
    "                self.tracked_objects[self.next_id] = {\n",
    "                    'position': center,\n",
    "                    'bbox': bbox,\n",
    "                    'class': class_name,\n",
    "                    'first_seen': current_time,\n",
    "                    'last_seen': current_time,\n",
    "                    'static_time': 0,\n",
    "                    'owner_nearby': owner_nearby,\n",
    "                    'last_owner_time': current_time\n",
    "                }\n",
    "                self.next_id += 1\n",
    "        \n",
    "        for obj_id, obj_data in self.tracked_objects.items():\n",
    "            if obj_data['owner_nearby']:\n",
    "                obj_data['last_owner_time'] = current_time\n",
    "        \n",
    "        to_remove = []\n",
    "        for obj_id, obj_data in self.tracked_objects.items():\n",
    "            if current_time - obj_data['last_seen'] > 5:\n",
    "                to_remove.append(obj_id)\n",
    "        \n",
    "        for obj_id in to_remove:\n",
    "            del self.tracked_objects[obj_id]\n",
    "            if obj_id in self.abandoned_objects:\n",
    "                del self.abandoned_objects[obj_id]\n",
    "        \n",
    "        return self.abandoned_objects\n",
    "\n",
    "print(\"‚úÖ Abandoned Object Detector class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Alert System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlertSystem:\n",
    "    def __init__(self):\n",
    "        self.alerts = []\n",
    "        self.alert_cooldown = {}\n",
    "    \n",
    "    def add_alert(self, alert_type, message, severity=\"INFO\"):\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        alert_key = f\"{alert_type}_{message}\"\n",
    "        current_time = time.time()\n",
    "        \n",
    "        if alert_key in self.alert_cooldown:\n",
    "            if current_time - self.alert_cooldown[alert_key] < 10:\n",
    "                return\n",
    "        \n",
    "        self.alert_cooldown[alert_key] = current_time\n",
    "        \n",
    "        alert = {\n",
    "            'timestamp': timestamp,\n",
    "            'type': alert_type,\n",
    "            'message': message,\n",
    "            'severity': severity\n",
    "        }\n",
    "        self.alerts.append(alert)\n",
    "        \n",
    "        severity_symbol = \"‚ö†Ô∏è\" if severity == \"WARNING\" else \"üö®\" if severity == \"CRITICAL\" else \"‚ÑπÔ∏è\"\n",
    "        print(f\"{severity_symbol} [{timestamp}] {alert_type}: {message}\")\n",
    "    \n",
    "    def get_recent_alerts(self, n=5):\n",
    "        return self.alerts[-n:] if len(self.alerts) >= n else self.alerts\n",
    "\n",
    "alert_system = AlertSystem()\n",
    "print(\"‚úÖ Alert System initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Main Video Analytics Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_dashboard(frame, rois, total_people, abandoned_count, fps, alerts):\n",
    "    h, w = frame.shape[:2]\n",
    "    \n",
    "    overlay = frame.copy()\n",
    "    cv2.rectangle(overlay, (10, 10), (400, 200), (0, 0, 0), -1)\n",
    "    frame = cv2.addWeighted(overlay, 0.7, frame, 0.3, 0)\n",
    "    \n",
    "    cv2.putText(frame, \"Airport Security Analytics\", (20, 35),\n",
    "                config.FONT, 0.7, (255, 255, 255), 2)\n",
    "    \n",
    "    cv2.putText(frame, f\"Total People: {total_people}\", (20, 65),\n",
    "                config.FONT, 0.5, (255, 255, 255), 1)\n",
    "    cv2.putText(frame, f\"Abandoned Objects: {abandoned_count}\", (20, 90),\n",
    "                config.FONT, 0.5, (255, 100, 100) if abandoned_count > 0 else (255, 255, 255), 1)\n",
    "    cv2.putText(frame, f\"FPS: {fps:.1f}\", (20, 115),\n",
    "                config.FONT, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    y_offset = 140\n",
    "    for roi in rois:\n",
    "        status_text = f\"{roi.name}: {roi.person_count} ({roi.status})\"\n",
    "        cv2.putText(frame, status_text, (20, y_offset),\n",
    "                    config.FONT, 0.4, roi.color, 1)\n",
    "        y_offset += 20\n",
    "    \n",
    "    if alerts:\n",
    "        alert_overlay = frame.copy()\n",
    "        cv2.rectangle(alert_overlay, (w - 410, h - 110), (w - 10, h - 10), (0, 0, 0), -1)\n",
    "        frame = cv2.addWeighted(alert_overlay, 0.7, frame, 0.3, 0)\n",
    "        \n",
    "        cv2.putText(frame, \"Recent Alerts:\", (w - 400, h - 90),\n",
    "                    config.FONT, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        for idx, alert in enumerate(alerts[-3:]):\n",
    "            alert_text = f\"{alert['type'][:20]}...\"\n",
    "            color = (0, 255, 255) if alert['severity'] == \"WARNING\" else (0, 0, 255)\n",
    "            cv2.putText(frame, alert_text, (w - 400, h - 65 + idx * 20),\n",
    "                        config.FONT, 0.4, color, 1)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, output_path=None, max_frames=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"‚ùå Error: Cannot open video file {video_path}\")\n",
    "        return\n",
    "    \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps_video = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"\\nüìπ Video Info:\")\n",
    "    print(f\"   Resolution: {frame_width}x{frame_height}\")\n",
    "    print(f\"   FPS: {fps_video}\")\n",
    "    print(f\"   Total Frames: {total_frames}\")\n",
    "    \n",
    "    rois = create_default_rois(frame_width, frame_height)\n",
    "    abandoned_detector = AbandonedObjectDetector()\n",
    "    \n",
    "    writer = None\n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        writer = cv2.VideoWriter(output_path, fourcc, fps_video, (frame_width, frame_height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    start_time = time.time()\n",
    "    fps_deque = deque(maxlen=30)\n",
    "    \n",
    "    print(\"\\nüöÄ Starting video processing...\\n\")\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "            if max_frames and frame_count > max_frames:\n",
    "                break\n",
    "            \n",
    "            frame_start = time.time()\n",
    "            current_time = time.time() - start_time\n",
    "            \n",
    "            results = model(frame, conf=config.CONFIDENCE_THRESHOLD, \n",
    "                          iou=config.IOU_THRESHOLD, verbose=False)[0]\n",
    "            \n",
    "            person_positions = []\n",
    "            object_detections = []\n",
    "            \n",
    "            for box in results.boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                conf = float(box.conf[0])\n",
    "                cls = int(box.cls[0])\n",
    "                class_name = class_names[cls]\n",
    "                \n",
    "                center_x = (x1 + x2) // 2\n",
    "                center_y = (y1 + y2) // 2\n",
    "                \n",
    "                if class_name == 'person':\n",
    "                    person_positions.append((center_x, center_y))\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f\"Person {conf:.2f}\", (x1, y1 - 10),\n",
    "                               config.FONT, 0.5, (0, 255, 0), 1)\n",
    "                else:\n",
    "                    object_detections.append(((x1, y1, x2, y2), class_name))\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
    "                    cv2.putText(frame, f\"{class_name} {conf:.2f}\", (x1, y1 - 10),\n",
    "                               config.FONT, 0.4, (255, 255, 0), 1)\n",
    "            \n",
    "            abandoned_objects = abandoned_detector.update(\n",
    "                object_detections, person_positions, current_time\n",
    "            )\n",
    "            \n",
    "            for obj_id, obj_data in abandoned_objects.items():\n",
    "                x1, y1, x2, y2 = obj_data['bbox']\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), config.COLOR_ABANDONED, 3)\n",
    "                cv2.putText(frame, \"ABANDONED!\", (x1, y1 - 25),\n",
    "                           config.FONT, 0.6, config.COLOR_ABANDONED, 2)\n",
    "                \n",
    "                time_abandoned = int(current_time - obj_data['abandoned_time'])\n",
    "                cv2.putText(frame, f\"{time_abandoned}s\", (x1, y1 - 5),\n",
    "                           config.FONT, 0.5, config.COLOR_ABANDONED, 1)\n",
    "                \n",
    "                alert_system.add_alert(\n",
    "                    \"ABANDONED OBJECT\",\n",
    "                    f\"{obj_data['class']} at ({obj_data['position'][0]}, {obj_data['position'][1]})\",\n",
    "                    \"CRITICAL\"\n",
    "                )\n",
    "            \n",
    "            for roi in rois:\n",
    "                roi.person_count = 0\n",
    "                for px, py in person_positions:\n",
    "                    if roi.is_point_inside((px, py)):\n",
    "                        roi.person_count += 1\n",
    "                        cv2.circle(frame, (px, py), 5, roi.color, -1)\n",
    "                \n",
    "                status = roi.update_status()\n",
    "                cv2.polylines(frame, [roi.polygon], True, roi.color, 2)\n",
    "                \n",
    "                label_pos = tuple(roi.polygon[0])\n",
    "                cv2.putText(frame, f\"{roi.name}: {roi.person_count}\", label_pos,\n",
    "                           config.FONT, 0.6, roi.color, 2)\n",
    "                \n",
    "                if status == \"OVERCROWDED\":\n",
    "                    alert_system.add_alert(\n",
    "                        \"OVERCROWDING\",\n",
    "                        f\"{roi.name} has {roi.person_count} people (threshold: {config.OVERCROWDING_THRESHOLD})\",\n",
    "                        \"CRITICAL\"\n",
    "                    )\n",
    "                elif status == \"HIGH DENSITY\":\n",
    "                    alert_system.add_alert(\n",
    "                        \"HIGH DENSITY\",\n",
    "                        f\"{roi.name} has {roi.person_count} people\",\n",
    "                        \"WARNING\"\n",
    "                    )\n",
    "            \n",
    "            frame_time = time.time() - frame_start\n",
    "            fps_deque.append(1.0 / frame_time if frame_time > 0 else 0)\n",
    "            avg_fps = sum(fps_deque) / len(fps_deque)\n",
    "            \n",
    "            frame = draw_dashboard(\n",
    "                frame, rois, len(person_positions),\n",
    "                len(abandoned_objects), avg_fps,\n",
    "                alert_system.get_recent_alerts()\n",
    "            )\n",
    "            \n",
    "            if writer:\n",
    "                writer.write(frame)\n",
    "            \n",
    "            if frame_count % 30 == 0:\n",
    "                print(f\"\\rProcessed: {frame_count}/{total_frames if not max_frames else max_frames} frames | \"\n",
    "                      f\"FPS: {avg_fps:.1f} | People: {len(person_positions)} | \"\n",
    "                      f\"Abandoned: {len(abandoned_objects)}\", end=\"\")\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n‚ö†Ô∏è Processing interrupted by user\")\n",
    "    \n",
    "    finally:\n",
    "        cap.release()\n",
    "        if writer:\n",
    "            writer.release()\n",
    "        \n",
    "        print(f\"\\n\\n‚úÖ Processing complete!\")\n",
    "        print(f\"   Processed {frame_count} frames\")\n",
    "        print(f\"   Total alerts generated: {len(alert_system.alerts)}\")\n",
    "        if output_path:\n",
    "            print(f\"   Output saved to: {output_path}\")\n",
    "\n",
    "print(\"‚úÖ Video processing pipeline defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Upload Test Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"Upload your video file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "video_path = list(uploaded.keys())[0]\n",
    "print(f\"‚úÖ Video uploaded: {video_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Run Video Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video_path = \"output_analyzed.mp4\"\n",
    "\n",
    "process_video(\n",
    "    video_path=video_path,\n",
    "    output_path=output_video_path,\n",
    "    max_frames=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(output_video_path):\n",
    "    files.download(output_video_path)\n",
    "    print(f\"‚úÖ Download started: {output_video_path}\")\n",
    "else:\n",
    "    print(\"‚ùå Output video not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Generate Alert Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if alert_system.alerts:\n",
    "    df_alerts = pd.DataFrame(alert_system.alerts)\n",
    "    \n",
    "    print(\"\\nüìä ALERT SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Total Alerts: {len(df_alerts)}\")\n",
    "    print(f\"\\nAlerts by Type:\")\n",
    "    print(df_alerts['type'].value_counts())\n",
    "    print(f\"\\nAlerts by Severity:\")\n",
    "    print(df_alerts['severity'].value_counts())\n",
    "    \n",
    "    print(\"\\n\\nüìã RECENT ALERTS (Last 10)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(df_alerts[['timestamp', 'type', 'message', 'severity']].tail(10).to_string(index=False))\n",
    "    \n",
    "    report_path = \"alert_report.csv\"\n",
    "    df_alerts.to_csv(report_path, index=False)\n",
    "    print(f\"\\n‚úÖ Alert report saved to: {report_path}\")\n",
    "    \n",
    "    files.download(report_path)\n",
    "else:\n",
    "    print(\"No alerts generated during processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualize Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if alert_system.alerts:\n",
    "    df = pd.DataFrame(alert_system.alerts)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    df['type'].value_counts().plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "    axes[0].set_title('Alert Types Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Alert Type')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    severity_colors = {'INFO': 'green', 'WARNING': 'orange', 'CRITICAL': 'red'}\n",
    "    severity_counts = df['severity'].value_counts()\n",
    "    colors = [severity_colors.get(sev, 'gray') for sev in severity_counts.index]\n",
    "    severity_counts.plot(kind='pie', ax=axes[1], autopct='%1.1f%%', colors=colors)\n",
    "    axes[1].set_title('Alert Severity Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_ylabel('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('alert_statistics.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ Visualization saved as alert_statistics.png\")\n",
    "    files.download('alert_statistics.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Project Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_text = f\"Airport/Station Video Analytics System\\n\"\n",
    "summary_text += f\"=====================================\\n\\n\"\n",
    "summary_text += f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
    "summary_text += f\"Model: YOLOv8n (Nano)\\n\"\n",
    "summary_text += f\"Framework: Ultralytics YOLO + OpenCV\\n\\n\"\n",
    "summary_text += f\"CAPABILITIES:\\n\"\n",
    "summary_text += f\"- Real-time people detection and counting\\n\"\n",
    "summary_text += f\"- Crowd density monitoring with zone-based analysis\\n\"\n",
    "summary_text += f\"- Overcrowding detection with configurable thresholds\\n\"\n",
    "summary_text += f\"- Abandoned object detection (bags, luggage, etc.)\\n\"\n",
    "summary_text += f\"- Automated alert system with severity levels\\n\"\n",
    "summary_text += f\"- Multi-zone Region of Interest (ROI) monitoring\\n\\n\"\n",
    "summary_text += f\"Total Alerts Generated: {len(alert_system.alerts)}\\n\"\n",
    "\n",
    "print(summary_text)\n",
    "\n",
    "with open('project_summary.txt', 'w') as f:\n",
    "    f.write(summary_text)\n",
    "\n",
    "print(\"\\n‚úÖ Project summary saved!\")\n",
    "files.download('project_summary.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Learning Resources & Next Steps\n",
    "\n",
    "### Key Concepts Covered:\n",
    "1. **Object Detection**: YOLOv8 for real-time detection\n",
    "2. **Object Tracking**: Proximity-based tracking\n",
    "3. **Spatial Analysis**: ROI-based zone monitoring\n",
    "4. **Temporal Analysis**: Time-based abandonment detection\n",
    "5. **Alert Systems**: Multi-level severity alerts\n",
    "\n",
    "### Future Enhancements:\n",
    "- Add DeepSORT for better object tracking\n",
    "- Implement trajectory analysis\n",
    "- Add behavior recognition (fighting, running)\n",
    "- Integrate with databases (MongoDB, PostgreSQL)\n",
    "- Build REST API with Flask/FastAPI\n",
    "- Create web dashboard with real-time updates\n",
    "- Add email/SMS notifications\n",
    "- Implement multi-camera fusion\n",
    "\n",
    "### Deployment Options:\n",
    "- **Edge**: NVIDIA Jetson Nano/Xavier\n",
    "- **Cloud**: AWS/GCP/Azure with Docker\n",
    "- **Hybrid**: Edge detection + Cloud analytics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
